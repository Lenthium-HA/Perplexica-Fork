[GENERAL]
SIMILARITY_MEASURE = "cosine" # "cosine" or "dot"
KEEP_ALIVE = "5m" # How long to keep Ollama models loaded into memory. (Instead of using -1 use "-1m")

[MODELS.OPENAI]
API_KEY = ""
DEFAULT_MODEL = "gpt-3.5-turbo" # Default: gpt-3.5-turbo, Options: gpt-3.5-turbo, gpt-4, gpt-4-turbo, gpt-4o, gpt-4o-mini, gpt-4.1-nano, gpt-4.1-mini, gpt-4.1, gpt-5-nano, gpt-5-mini, gpt-5

[MODELS.GROQ]
API_KEY = ""
DEFAULT_MODEL = "llama-3.1-70b-versatile" # Default: llama-3.1-70b-versatile, Options: llama-3.1-70b-versatile, llama-3.1-8b-instant, mixtral-8x7b-instruct

[MODELS.ANTHROPIC]
API_KEY = ""
DEFAULT_MODEL = "claude-3-sonnet-20240229" # Default: claude-3-sonnet-20240229, Options: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307

[MODELS.GEMINI]
API_KEY = ""
DEFAULT_MODEL = "gemini-1.5-flash" # Default: gemini-1.5-flash, Options: gemini-1.5-flash, gemini-1.5-pro, gemini-1.0-pro

[MODELS.CUSTOM_OPENAI]
API_KEY = ""
API_URL = ""
MODEL_NAME = ""

[MODELS.OLLAMA]
API_URL = "" # Ollama API URL - http://host.docker.internal:11434

[MODELS.DEEPSEEK]
API_KEY = ""

[MODELS.AIMLAPI]
API_KEY = "" # Required to use AI/ML API chat and embedding models

[MODELS.LM_STUDIO]
API_URL = "" # LM Studio API URL - http://host.docker.internal:1234

[API_ENDPOINTS]
SEARXNG = "" # SearxNG API URL - http://localhost:32768
